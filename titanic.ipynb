{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wfXxwvG_eUPM",
    "outputId": "ca4d95ec-df3a-41dc-e166-4063cc11877a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   PassengerId  Survived  Pclass  \\\n",
      "0          892         0       3   \n",
      "1          893         1       3   \n",
      "2          894         0       2   \n",
      "3          895         0       3   \n",
      "4          896         1       3   \n",
      "\n",
      "                                           Name     Sex   Age  SibSp  Parch  \\\n",
      "0                              Kelly, Mr. James    male  34.5      0      0   \n",
      "1              Wilkes, Mrs. James (Ellen Needs)  female  47.0      1      0   \n",
      "2                     Myles, Mr. Thomas Francis    male  62.0      0      0   \n",
      "3                              Wirz, Mr. Albert    male  27.0      0      0   \n",
      "4  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female  22.0      1      1   \n",
      "\n",
      "    Ticket     Fare Cabin Embarked  \n",
      "0   330911   7.8292   NaN        Q  \n",
      "1   363272   7.0000   NaN        S  \n",
      "2   240276   9.6875   NaN        Q  \n",
      "3   315154   8.6625   NaN        S  \n",
      "4  3101298  12.2875   NaN        S  \n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"titanic.csv\")\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 559
    },
    "id": "Z_rTOP8heogf",
    "outputId": "fd718bd0-4677-49d0-f345-c918cb1dfe4a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If file is local → Upload now\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'files' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 5\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf file is local → Upload now\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 5\u001b[0m uploaded \u001b[38;5;241m=\u001b[39m \u001b[43mfiles\u001b[49m\u001b[38;5;241m.\u001b[39mupload()\n\u001b[0;32m      7\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(uploaded\u001b[38;5;241m.\u001b[39mkeys())[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoaded file:\u001b[39m\u001b[38;5;124m\"\u001b[39m, filename)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'files' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from tkinter import Tk\n",
    "from tkinter.filedialog import askopenfilename\n",
    "\n",
    "# Hide the main Tkinter window\n",
    "Tk().withdraw()\n",
    "\n",
    "file_path = askopenfilename(title=\"Select CSV File\")\n",
    "print(\"Loaded file:\", file_path)\n",
    "\n",
    "df = pd.read_csv(file_path)\n",
    "print(\"Dataset Shape:\", df.shape)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "ke_0-OhWetcl",
    "outputId": "4206bdfa-da67-4fe1-83dc-5b6668c286ec"
   },
   "outputs": [],
   "source": [
    "df = df.copy()\n",
    "\n",
    "# Drop columns not useful for survival prediction\n",
    "cols_to_drop = [\"Name\", \"Ticket\", \"Cabin\"]\n",
    "for c in cols_to_drop:\n",
    "    if c in df.columns:\n",
    "        df.drop(columns=c, inplace=True)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GlI9iYace9yf",
    "outputId": "93c1a0b6-3fc9-4b35-b3c4-c584691e683f"
   },
   "outputs": [],
   "source": [
    "# Fill Age missing values with median\n",
    "if \"Age\" in df.columns:\n",
    "    df[\"Age\"].fillna(df[\"Age\"].median(), inplace=True)\n",
    "\n",
    "# Fill Embarked missing values with mode (most common)\n",
    "if \"Embarked\" in df.columns:\n",
    "    df[\"Embarked\"].fillna(df[\"Embarked\"].mode()[0], inplace=True)\n",
    "\n",
    "print(df.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "m4nYpUTofAvD"
   },
   "outputs": [],
   "source": [
    "X = df.drop(\"Survived\", axis=1)\n",
    "y = df[\"Survived\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Wiq8UryLfDue",
    "outputId": "e134fe42-1249-4533-b46e-a8c1a496a211"
   },
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "\n",
    "categorical_features = [\"Pclass\", \"Sex\", \"Embarked\"]\n",
    "\n",
    "numeric_features = [c for c in numeric_features if c in X.columns]\n",
    "categorical_features = [c for c in categorical_features if c in X.columns]\n",
    "\n",
    "print(\"Numeric:\", numeric_features)\n",
    "print(\"Categorical:\", categorical_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "452eSchtfGIK"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "numeric_transformer = Pipeline([\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline([\n",
    "    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer([\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nW9Hu-pufIsM",
    "outputId": "3556e108-c648-468a-88d3-7f960c451d4b"
   },
   "outputs": [],
   "source": [
    "# Inspect missing values in X_train and X_test\n",
    "import pandas as pd\n",
    "print(\"Missing in entire dataset:\\n\", df.isna().sum())\n",
    "print(\"\\nMissing in X (features):\\n\", X.isna().sum())\n",
    "print(\"\\nMissing in X_train:\\n\", X_train.isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qZGTyVnVfLm3",
    "outputId": "52662fb2-9428-492f-9b36-270e698e578c"
   },
   "outputs": [],
   "source": [
    "# Preprocessing pipeline with imputers (replace the previous pipeline)\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
    "\n",
    "numeric_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"median\")),   # fills numeric NaNs with median\n",
    "    (\"scaler\", StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_transformer = Pipeline(steps=[\n",
    "    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),  # fills categorical NaNs with mode\n",
    "    (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\", sparse_output=False))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(transformers=[\n",
    "    (\"num\", numeric_transformer, numeric_features),\n",
    "    (\"cat\", categorical_transformer, categorical_features)\n",
    "], remainder=\"drop\")\n",
    "\n",
    "print(\"Preprocessor with imputation built.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "NsONPgk6fjwY",
    "outputId": "8fea9f63-3d3e-4e7a-ecd2-0005e14b6119"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "plt.figure(figsize=(5,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nxpJnf9Sfr5U",
    "outputId": "fd9a9e55-9d1b-4865-ef8c-d2da1bed0a36"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# If you have not already split, (re)create split to ensure X_train/X_test are in memory:\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "log_reg_model = Pipeline([\n",
    "    (\"preprocessor\", preprocessor),\n",
    "    (\"classifier\", LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "log_reg_model.fit(X_train, y_train)\n",
    "print(\"Model trained successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 618
    },
    "id": "K_b0yjS0geww",
    "outputId": "1574415f-e61d-413f-d18c-9bc763d8623e"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Predictions\n",
    "y_pred = log_reg_model.predict(X_test)\n",
    "\n",
    "# Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Detailed metrics\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
    "plt.title(\"Titanic Survival Prediction — Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xxPLQwd0gsgn",
    "outputId": "8fd0d8a0-07ff-443f-840b-42ef62413f4c"
   },
   "outputs": [],
   "source": [
    "print(df.head(10))\n",
    "print(\"\\nColumns:\", df.columns.tolist())\n",
    "\n",
    "# Check if Survived is mistakenly included in X\n",
    "print(\"\\nDoes X contain Survived?\", \"Survived\" in X.columns)\n",
    "\n",
    "# Check for duplicates between X_train and X_test\n",
    "dup = pd.merge(X_train.reset_index(), X_test.reset_index(), how='inner')\n",
    "print(\"\\nOverlapping rows between train and test:\", dup.shape[0])\n",
    "\n",
    "# Check class distribution\n",
    "print(\"\\nTarget distribution:\")\n",
    "print(df['Survived'].value_counts())\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
